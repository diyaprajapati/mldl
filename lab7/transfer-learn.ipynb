{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818e7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61dd590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06cc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 2. Load Dataset --------------------\n",
    "(num_classes, base_input_shape) = (10, (32,32,3))\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "y_train = y_train.flatten()\n",
    "y_test  = y_test.flatten()\n",
    "\n",
    "# Train/Val Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.1, random_state=SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "# Ensure RGB (3 channels)\n",
    "if x_train.shape[-1] == 1:  # sometimes grayscale by accident\n",
    "    x_train = np.repeat(x_train, 3, axis=-1)\n",
    "    x_val   = np.repeat(x_val, 3, axis=-1)\n",
    "    x_test  = np.repeat(x_test, 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ba6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "preprocess = keras.applications.efficientnet.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02f78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(x, y, train=False, batch_size=64):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    if train:\n",
    "        ds = ds.shuffle(10000, seed=SEED)\n",
    "    # Resize and preprocess\n",
    "    ds = ds.map(lambda a, b: (tf.image.resize(a, (IMG_SIZE, IMG_SIZE)), b),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(lambda a, b: (preprocess(a), b), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if train:\n",
    "        # Light augmentation\n",
    "        aug = keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(0.05),\n",
    "            layers.RandomZoom(0.1),\n",
    "        ])\n",
    "        ds = ds.map(lambda a, b: (aug(a, training=True), b),\n",
    "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40fd70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_ds(x_train, y_train, train=True, batch_size=128)\n",
    "val_ds   = make_ds(x_val,   y_val,   train=False, batch_size=128)\n",
    "test_ds  = make_ds(x_test,  y_test,  train=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b93f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force 3 channels in the model definition\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base = keras.applications.EfficientNetB0(\n",
    "    include_top=False, weights=None, input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "base.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb84ec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"efficientnetb0_cifar10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"efficientnetb0_cifar10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m12,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,062,381</span> (15.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,062,381\u001b[0m (15.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> (50.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,810\u001b[0m (50.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_tl = keras.Model(inputs, outputs, name=\"efficientnetb0_cifar10\")\n",
    "\n",
    "model_tl.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af24e1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 1] Training head only...\n",
      "Epoch 1/5\n",
      "352/352 - 1075s - 3s/step - accuracy: 0.0982 - loss: 2.3026 - val_accuracy: 0.1206 - val_loss: 2.3024\n",
      "Epoch 2/5\n",
      "352/352 - 912s - 3s/step - accuracy: 0.1088 - loss: 2.3024 - val_accuracy: 0.1240 - val_loss: 2.3022\n",
      "Epoch 3/5\n",
      "352/352 - 896s - 3s/step - accuracy: 0.1160 - loss: 2.3022 - val_accuracy: 0.1454 - val_loss: 2.3020\n",
      "Epoch 4/5\n",
      "352/352 - 621s - 2s/step - accuracy: 0.1268 - loss: 2.3020 - val_accuracy: 0.1476 - val_loss: 2.3018\n",
      "Epoch 5/5\n",
      "352/352 - 582s - 2s/step - accuracy: 0.1278 - loss: 2.3018 - val_accuracy: 0.1542 - val_loss: 2.3016\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 5. Warmup Training --------------------\n",
    "print(\"\\n[Stage 1] Training head only...\")\n",
    "warmup = model_tl.fit(\n",
    "    train_ds, validation_data=val_ds,\n",
    "    epochs=5, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ef7c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 2] Fine-tuning last 50 layers...\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 6. Fine-Tuning --------------------\n",
    "print(\"\\n[Stage 2] Fine-tuning last 50 layers...\")\n",
    "for layer in base.layers[-50:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "model_tl.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a50eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "352/352 - 697s - 2s/step - accuracy: 0.1394 - loss: 2.2218 - val_accuracy: 0.1820 - val_loss: 2.1128\n",
      "Epoch 2/20\n",
      "352/352 - 746s - 2s/step - accuracy: 0.1949 - loss: 2.1244 - val_accuracy: 0.2446 - val_loss: 2.0558\n",
      "Epoch 3/20\n",
      "352/352 - 690s - 2s/step - accuracy: 0.2250 - loss: 2.0850 - val_accuracy: 0.2450 - val_loss: 2.0383\n",
      "Epoch 4/20\n",
      "352/352 - 737s - 2s/step - accuracy: 0.2324 - loss: 2.0632 - val_accuracy: 0.2466 - val_loss: 2.0189\n",
      "Epoch 5/20\n",
      "352/352 - 693s - 2s/step - accuracy: 0.2379 - loss: 2.0505 - val_accuracy: 0.2528 - val_loss: 2.0049\n",
      "Epoch 6/20\n",
      "352/352 - 700s - 2s/step - accuracy: 0.2416 - loss: 2.0407 - val_accuracy: 0.2554 - val_loss: 1.9960\n",
      "Epoch 7/20\n",
      "352/352 - 701s - 2s/step - accuracy: 0.2417 - loss: 2.0326 - val_accuracy: 0.2572 - val_loss: 1.9978\n",
      "Epoch 8/20\n",
      "352/352 - 699s - 2s/step - accuracy: 0.2468 - loss: 2.0259 - val_accuracy: 0.2544 - val_loss: 1.9988\n",
      "Epoch 9/20\n",
      "352/352 - 732s - 2s/step - accuracy: 0.2469 - loss: 2.0191 - val_accuracy: 0.2658 - val_loss: 1.9791\n",
      "Epoch 10/20\n",
      "352/352 - 777s - 2s/step - accuracy: 0.2495 - loss: 2.0145 - val_accuracy: 0.2634 - val_loss: 1.9759\n",
      "Epoch 11/20\n",
      "352/352 - 778s - 2s/step - accuracy: 0.2488 - loss: 2.0093 - val_accuracy: 0.2670 - val_loss: 1.9772\n",
      "Epoch 12/20\n",
      "352/352 - 951s - 3s/step - accuracy: 0.2497 - loss: 2.0067 - val_accuracy: 0.2692 - val_loss: 1.9647\n",
      "Epoch 13/20\n",
      "352/352 - 958s - 3s/step - accuracy: 0.2532 - loss: 1.9985 - val_accuracy: 0.2668 - val_loss: 1.9675\n",
      "Epoch 14/20\n",
      "352/352 - 1003s - 3s/step - accuracy: 0.2513 - loss: 1.9969 - val_accuracy: 0.2676 - val_loss: 1.9582\n",
      "Epoch 15/20\n",
      "352/352 - 1014s - 3s/step - accuracy: 0.2550 - loss: 1.9873 - val_accuracy: 0.2704 - val_loss: 1.9600\n",
      "Epoch 16/20\n",
      "352/352 - 1011s - 3s/step - accuracy: 0.2558 - loss: 1.9830 - val_accuracy: 0.2726 - val_loss: 1.9428\n",
      "Epoch 17/20\n",
      "352/352 - 1278s - 4s/step - accuracy: 0.2588 - loss: 1.9756 - val_accuracy: 0.2742 - val_loss: 1.9500\n",
      "Epoch 18/20\n",
      "352/352 - 826s - 2s/step - accuracy: 0.2612 - loss: 1.9735 - val_accuracy: 0.2758 - val_loss: 1.9388\n",
      "Epoch 19/20\n",
      "352/352 - 842s - 2s/step - accuracy: 0.2629 - loss: 1.9684 - val_accuracy: 0.2796 - val_loss: 1.9375\n",
      "Epoch 20/20\n",
      "352/352 - 729s - 2s/step - accuracy: 0.2652 - loss: 1.9646 - val_accuracy: 0.2852 - val_loss: 1.9339\n"
     ]
    }
   ],
   "source": [
    "early = keras.callbacks.EarlyStopping(\n",
    "    patience=5, restore_best_weights=True, monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "fine = model_tl.fit(\n",
    "    train_ds, validation_data=val_ds,\n",
    "    epochs=20, callbacks=[early], verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1875585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage 3] Evaluating on test set...\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 7. Evaluation --------------------\n",
    "print(\"\\n[Stage 3] Evaluating on test set...\")\n",
    "probs = model_tl.predict(test_ds, verbose=0)\n",
    "y_pred = probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6899f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EfficientNetB0 TL] Test Accuracy: 0.2899\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3485    0.4140    0.3784      1000\n",
      "           1     0.3279    0.3400    0.3338      1000\n",
      "           2     0.1552    0.0430    0.0673      1000\n",
      "           3     0.1268    0.0090    0.0168      1000\n",
      "           4     0.2176    0.2690    0.2406      1000\n",
      "           5     0.2628    0.3740    0.3087      1000\n",
      "           6     0.2784    0.5900    0.3783      1000\n",
      "           7     0.2350    0.2390    0.2370      1000\n",
      "           8     0.3432    0.2660    0.2997      1000\n",
      "           9     0.4142    0.3550    0.3823      1000\n",
      "\n",
      "    accuracy                         0.2899     10000\n",
      "   macro avg     0.2710    0.2899    0.2643     10000\n",
      "weighted avg     0.2710    0.2899    0.2643     10000\n",
      "\n",
      "Confusion matrix:\n",
      " [[414  74  11  10  25 116  39  86 178  47]\n",
      " [ 74 340   8   6  20  44  82  81 103 242]\n",
      " [109  37  43  10 213 189 276  72  38  13]\n",
      " [ 57  60  54   9 173 264 208 145  13  17]\n",
      " [ 33  24  36   4 269 115 415  71  23  10]\n",
      " [ 88  32  43  11 167 374 187  76  15   7]\n",
      " [  7  25  24   2 190  65 590  86   1  10]\n",
      " [ 58  70  41   9 161 135 197 239  28  62]\n",
      " [275 153   9   6  13  95  21  68 266  94]\n",
      " [ 73 222   8   4   5  26 104  93 110 355]]\n"
     ]
    }
   ],
   "source": [
    "# Align true labels with test_ds order\n",
    "y_true_list = []\n",
    "for _, yb in test_ds:\n",
    "    y_true_list.append(yb.numpy())\n",
    "y_true = np.concatenate(y_true_list, axis=0)\n",
    "\n",
    "acc = (y_pred == y_true).mean()\n",
    "print(f\"[EfficientNetB0 TL] Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "419243ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision: 0.2710 | Macro Recall: 0.2899 | Macro F1: 0.2643\n",
      "Micro Precision: 0.2899 | Micro Recall: 0.2899 | Micro F1: 0.2899\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "print(f\"Macro Precision: {prec:.4f} | Macro Recall: {rec:.4f} | Macro F1: {f1:.4f}\")\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(f\"Micro Precision: {prec:.4f} | Micro Recall: {rec:.4f} | Micro F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04596df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (macro, OVR): 0.7625 | ROC-AUC (macro, OVO): 0.7625\n"
     ]
    }
   ],
   "source": [
    "# ROC-AUC\n",
    "y_true_oh = keras.utils.to_categorical(y_true, num_classes)\n",
    "try:\n",
    "    auc_ovr = roc_auc_score(y_true_oh, probs, average=\"macro\", multi_class=\"ovr\")\n",
    "    auc_ovo = roc_auc_score(y_true_oh, probs, average=\"macro\", multi_class=\"ovo\")\n",
    "    print(f\"ROC-AUC (macro, OVR): {auc_ovr:.4f} | ROC-AUC (macro, OVO): {auc_ovo:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"ROC-AUC could not be computed:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
